{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. mp3 -> wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58000/58000 [54:19<00:00, 17.79it/s]  \n"
     ]
    }
   ],
   "source": [
    "import os, tqdm, shutil\n",
    "\n",
    "subset = \"train\"\n",
    "# subset = \"valid\"\n",
    "# subset = \"test.2016\"\n",
    "# subset = \"test.2017\"\n",
    "# subset = \"test.coco\"\n",
    "\n",
    "mp3_root = \"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/16khz_wav/es_mp3\"\n",
    "wav_root = \"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/16khz_wav/es\"\n",
    "os.makedirs(os.path.join(wav_root, subset), exist_ok=True)\n",
    "for file in tqdm.tqdm(os.listdir(os.path.join(mp3_root, subset))):\n",
    "    if file.endswith(\".json\"):\n",
    "        shutil.copy(\n",
    "            os.path.join(mp3_root, subset, file), os.path.join(wav_root, subset, file)\n",
    "        )\n",
    "    elif file.endswith(\".mp3\"):\n",
    "        cmd = f\"ffmpeg -i {os.path.join(mp3_root, subset, file)} -ar 16000 {os.path.join(wav_root, subset, file[:-4] + '.wav')} -loglevel quiet\"\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "from pydub import AudioSegment\n",
    "subset = \"train\"\n",
    "wav_root = \"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/16khz_wav/es\"\n",
    "wavs = glob.glob(f\"{os.path.join(wav_root, subset)}/*.wav\")\n",
    "print(len(wavs))\n",
    "wav = wavs[0]\n",
    "audio = AudioSegment.from_wav(wav)\n",
    "print(audio.frame_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. manifest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quantize using the learned clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. postprocess quatized txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "\n",
    "# subset = \"train\"\n",
    "# subset = \"valid\"\n",
    "# subset = \"test.2016\"\n",
    "# subset = \"test.2017\"\n",
    "subset = \"test.coco\"\n",
    "\n",
    "lang = \"es\"\n",
    "manifest_root = \"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/manifest\"\n",
    "manifest_dir = Path(manifest_root) / f\"{subset}.{lang}\"\n",
    "\n",
    "manifest_lines = []\n",
    "quantized_lines = []\n",
    "with open(manifest_dir / f\"{subset}.{lang}.tsv\", mode=\"r+\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1: ]:\n",
    "        manifest_lines.append(line.strip())\n",
    "with open(manifest_dir / f\"{subset}.{lang}.txt\", mode=\"r+\") as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        line = line.strip()\n",
    "        index, unit = line.split('|')\n",
    "        assert index == manifest_lines[i].split('\\t')[0].split('.')[0]\n",
    "        unit = unit.split()\n",
    "        unit = [k for k, _ in groupby(unit)]\n",
    "        unit = ' '.join([str(k) for k in unit])\n",
    "        quantized_lines.append(index + \"|\" + unit)\n",
    "        # print(quantized_lines[-1])\n",
    "with open(manifest_dir / f\"{subset}.{lang}.txt\", mode=\"w+\") as f:\n",
    "    f.write('\\n'.join(quantized_lines))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. generate es-en tsv from es and en source_unit tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "\n",
    "# src_lang, tgt_lang = \"es\", \"en\"\n",
    "# src_lang, tgt_lang = \"en\", \"fr\"\n",
    "src_lang, tgt_lang = \"en\", \"es\"\n",
    "\n",
    "# subset = \"train\"\n",
    "# subset = \"valid\"\n",
    "# subset = \"test.2016\"\n",
    "# subset = \"test.2017\"\n",
    "subset = \"test.coco\"\n",
    "\n",
    "output_manifest_root = f\"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/format_data/{src_lang}-{tgt_lang}\"\n",
    "\n",
    "src_manifest_root = f\"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/format_data/{src_lang}-{tgt_lang}/{src_lang}_source_unit\"\n",
    "src_manifest_path = Path(src_manifest_root) / f\"{subset}.tsv\"\n",
    "\n",
    "tgt_manifest_root = \"/opt/data/private/dsy/project/dataset/multi30k-dataset/data/speech/manifest\"\n",
    "tgt_manifest_dir = Path(tgt_manifest_root) / f\"{subset}.{tgt_lang}\"\n",
    "\n",
    "src_tsv = pd.read_csv(src_manifest_path, sep='\\t')\n",
    "id2tgt_unit = {}\n",
    "tgt_unit = []\n",
    "tgt_size = []\n",
    "with open(tgt_manifest_dir / f\"{subset}.{tgt_lang}.txt\", mode=\"r+\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        index, unit = line.split('|')\n",
    "        id2tgt_unit[int(index)] = unit\n",
    "for i, row in src_tsv.iterrows():\n",
    "    unit = id2tgt_unit[row[\"id\"]]\n",
    "    tgt_unit.append(unit)\n",
    "    tgt_size.append(unit.count(' ') + 1)\n",
    "assert len(tgt_unit) == len(tgt_size) == src_tsv.shape[0]\n",
    "src_tsv[\"tgt_text\"] = tgt_unit\n",
    "src_tsv[\"tgt_n_frames\"] = tgt_size\n",
    "\n",
    "src_tsv.set_index(\"id\", inplace=True)\n",
    "src_tsv.to_csv(Path(output_manifest_root) / f\"{subset}.tsv\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
